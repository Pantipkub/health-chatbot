from dotenv import load_dotenv  
from langchain_core.messages import BaseMessage # The foundational class for all message types in LangGraph
from langchain_core.messages import ToolMessage # Passes data back to LLM after it calls a tool such as the content and the tool_call_id
from langchain_core.messages import SystemMessage # Message for providing instructions to the LLM
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.tools import tool
from langgraph.graph.message import add_messages
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from .state import AgentState
from .rag_utils import retrieve_context

load_dotenv()

@tool
def add(a: int, b:int):
    """This is an addition function that adds 2 numbers together"""

    return a + b 

@tool
def subtract(a: int, b: int):
    """Subtraction function"""
    return a - b

@tool
def multiply(a: int, b: int):
    """Multiplication function"""
    return a * b

# tools = [add, subtract, multiply]
tools = []

# model = ChatGoogleGenerativeAI(model="gemini-2.5-flash-lite").bind_tools(tools)

intent_model = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash-lite",
    temperature=0
)

chat_model = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash"
)


# ----- Function -----

def input_node(state: AgentState):
    """
    Entry node that receives user input and initializes debugging metadata.
    """
    
    state["current_node"] = "input_node"
    state["steps"].append("Received user input")

    last_msg = state["messages"][-1]
    print("User said:", last_msg.content)

    return state

def classify_intent_node(state: AgentState):
    """
    Analyze user message and classify medical intent using LLM.
    """

    state["current_node"] = "classify_intent"
    state["steps"].append("Classifying user intent with LLM")

    prompt = SystemMessage(content=
        "You are a medical triage assistant.\n"
        "Classify the user's intent into ONE of the following:\n"
        "- symptom\n"
        "- general_health\n"
        "- administrative\n\n"
        "Respond with only the label."
    )

    user_msg = state["messages"][-1]
    result = intent_model.invoke([prompt, user_msg])

    state["intent"] = result.content.strip().lower()
    return state

def route_by_intent(state):
    intent = state.get("intent")
    if intent in ("symptom", "general_health"):
        return intent
    return "general_health"  # fallback

# ----- Conditional -----
def should_continue(state: AgentState):
    """
    Decide whether to continue calling the tools.
    """

    messages = state["messages"]
    last_message = messages[-1]
    if not last_message.tool_calls: # ‡πÑ‡∏°‡πà‡∏°‡∏µ tool_calls ‡∏à‡∏≤‡∏Å LLM ‡πÅ‡∏•‡πâ‡∏ß = ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏∞‡∏ï‡∏≠‡∏ö User ‡πÅ‡∏•‡πâ‡∏ß

        return "end"
    else:
        return "continue"   # LLM ‡∏Ç‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ tool ‡∏≠‡∏¢‡∏π‡πà
    
def call_model(state: AgentState):
    """
    Node ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î (Thinking Process) ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ
    """
    messages = state["messages"]
    last_user_message = messages[-1].content 
    context = retrieve_context(last_user_message)
    
    if context:
        rag_prompt = (
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (Health Risk Screener)\n"
            "‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏±‡∏ß\n\n"
            "**‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:**\n"
            "1. üí≠ ‡∏Ñ‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏≠‡∏¢‡∏π‡πà: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏õ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Guideline ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡πÅ‡∏ó‡∏£‡∏Å‡∏ã‡πâ‡∏≠‡∏ô\n"
            "2. üìã ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•: ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á' ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÇ‡∏£‡∏Ñ\n"
            "3. üîç ‡∏Å‡∏≤‡∏£‡∏ñ‡∏≤‡∏°‡∏Å‡∏•‡∏±‡∏ö: ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏û‡∏≠ ‡πÉ‡∏´‡πâ‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Lifestyle (‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏¢, ‡∏Å‡∏≤‡∏£‡∏≠‡∏î‡∏≠‡∏≤‡∏´‡∏≤‡∏£, ‡πÇ‡∏£‡∏Ñ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ï‡∏±‡∏ß) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô\n"
            "4. üìâ Trend: ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏î‡πâ‡∏ß‡∏¢\n"
            "5. üë®‚Äç‚öïÔ∏è ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡πÄ‡∏ô‡πâ‡∏ô '‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°' ‡πÅ‡∏•‡∏∞ '‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏™‡πà‡∏á‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå'\n\n"
        )
    else:
        rag_prompt = (
            "‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏ú‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏π‡πÅ‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á '‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ï ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï ‡πÅ‡∏•‡∏∞‡πÑ‡∏Ç‡∏°‡∏±‡∏ô‡πÉ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î' ‡∏Ñ‡∏£‡∏±‡∏ö "
            "‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡∏°‡∏°‡∏µ "
            "‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô ‡∏™‡πà‡∏á‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏ú‡∏°‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö"
        )

    response = chat_model.invoke([SystemMessage(content=rag_prompt)] + messages)
    
    return {"messages": [response], "steps": ["retrieval", "generate"]}

# ----- Generate graph -----
def build_graph():
    graph = StateGraph(AgentState)

    # ----- add nodes -----
    graph.add_node("input", input_node)
    graph.add_node("classify_intent", classify_intent_node)
    graph.add_node("our_agent", call_model)

    tool_node = ToolNode(tools=tools)
    graph.add_node("tools", tool_node)

    # ----- entry point -----
    graph.set_entry_point("input")

    # ----- normal edges -----
    graph.add_edge("input", "classify_intent")

    # ----- routing by intent -----
    graph.add_conditional_edges(
        "classify_intent",
        route_by_intent,
        {
            "symptom": "our_agent",
            "general_health": "our_agent"
        }
    )

    # ----- tool loop (optional ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ tools = []) -----
    graph.add_conditional_edges(
        "our_agent",
        should_continue,
        {
            "continue": "tools",
            "end": END
        }
    )

    graph.add_edge("tools", "our_agent")

    app = graph.compile()

    return app
