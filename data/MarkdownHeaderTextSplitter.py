import os
import shutil
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_text_splitters import MarkdownHeaderTextSplitter

# --- Config ---
PERSIST_DIRECTORY = "./chroma_db_health"
FILES_TO_READ = [
    "diabetes_knowledge.md", 
    "kidney_knowledge.md"
] 

def main():
    print("=== ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Knowledge Base (‡∏£‡∏ß‡∏° 2 ‡πÇ‡∏£‡∏Ñ) ===")

    # 1. ‡∏•‡πâ‡∏≤‡∏á Database ‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏¥‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å! ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏à‡∏∞‡∏Ñ‡πâ‡∏≤‡∏á)
    if os.path.exists(PERSIST_DIRECTORY):
        print(f"üßπ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÉ‡∏ô {PERSIST_DIRECTORY}...")
        shutil.rmtree(PERSIST_DIRECTORY)
    
    # 2. ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Markdown ‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ß‡πâ
    all_text_data = ""
    for file_path in FILES_TO_READ:
        if os.path.exists(file_path):
            print(f"üìñ ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå: {file_path}")
            with open(file_path, "r", encoding="utf-8") as f:
                all_text_data += f.read() + "\n\n" # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏°‡∏≤‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô
        else:
            print(f"‚ö†Ô∏è ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå {file_path} ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ (‡∏Ç‡πâ‡∏≤‡∏°)")

    if not all_text_data:
        print("‚ùå Error: ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∞‡πÑ‡∏£‡∏°‡∏≤‡πÄ‡∏•‡∏¢ ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏î‡πà‡∏ß‡∏ô")
        return

    # 3. ‡∏ï‡∏±‡∏î‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Chunking)
    # ‡∏ï‡∏±‡∏î‡∏ó‡∏µ‡πà # (‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ) ‡πÅ‡∏•‡∏∞ ## (‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠)
    headers_to_split_on = [
        ("#", "Disease"),
        ("##", "Topic"),
    ]
    splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)
    all_chunks = splitter.split_text(all_text_data)
    
    print(f"‚úÖ ‡∏ï‡∏±‡∏î‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(all_chunks)} ‡∏ä‡∏¥‡πâ‡∏ô (‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 3 ‡∏ä‡∏¥‡πâ‡∏ô)")

    # 4. ‡πÇ‡∏´‡∏•‡∏î AI Model (Force CPU ‡πÅ‡∏Å‡πâ‡∏ö‡∏±‡πä‡∏Å Mac)
    print("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î AI Model...")
    embedding_function = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

    # 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Database
    print("üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á Database...")
    db = Chroma.from_documents(
        documents=all_chunks,
        embedding=embedding_function,
        persist_directory=PERSIST_DIRECTORY
    )

    print(f"üéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Database ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ: {db._collection.count()} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    
    # 6. Test ‡πÄ‡∏•‡∏¢‡∏ß‡πà‡∏≤‡πÄ‡∏à‡∏≠‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ï‡πÑ‡∏´‡∏°
    print("\n--- Test ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ï ---")
    results = db.similarity_search("‡∏Ñ‡πà‡∏≤ eGFR 40 ‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏¢‡∏∞‡πÑ‡∏´‡∏ô", k=2)
    for doc in results:
        print(f"Found: {doc.page_content[:100]}...")

if __name__ == "__main__":
    main()